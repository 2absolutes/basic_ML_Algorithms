{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5c90afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7660767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(weights, biases, inputs):\n",
    "    print(f\"\\n[DEBUG] linear_forward -----\")\n",
    "    \n",
    "    print(f\"[DEBUG] weights.shape: {weights.shape}, biases.shape: {biases.shape}, inputs.shape: {inputs.T.shape}\")\n",
    "    z = np.matmul(weights, inputs.T) + biases    \n",
    "    print(f\"[DEBUG] z.shape: {z.shape}\")\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "87f13f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_linear_forward(z):\n",
    "    print(f\"\\n[DEBUG] activation_linear_forward -----\")\n",
    "    \n",
    "    print(f\"[DEBUG] z.shape: {z.shape}\")\n",
    "    a = 1.0/(1.0 + np.exp(-z))\n",
    "    print(f\"[DEBUG] a.shape: {a.shape}\")\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f4cbc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, y_hat):\n",
    "    print(f\"\\n[DEBUG] cross_entropy_loss -----\")\n",
    "    \n",
    "    y = y.reshape(y_hat.shape)\n",
    "    \n",
    "    print(f\"[DEBUG] y.shape: {y.shape}, y_hat.shape: {y_hat.shape}\")\n",
    "    cross_entropy_loss = (-1/y.shape[1]) * np.sum((y * np.log(y_hat) + (1-y) * np.log(1-y_hat)))\n",
    "    return cross_entropy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "920ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(activations, y, X):\n",
    "    print(f\"\\n[DEBUG] calculate_gradient -----\")\n",
    "    \n",
    "    y = y.reshape(activations.shape)\n",
    "    \n",
    "    print(f\"[DEBUG] activations.shape: {activations.shape}, y.shape: {y.shape}, X.shape: {X.shape}\")\n",
    "    gradients = np.matmul((activations - y), X)\n",
    "    print(f\"[DEBUG] gradients.shape: {gradients.shape}\")\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6dd72e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, gradients, learning_rate):\n",
    "    print(f\"\\n[DEBUG] update_weights -----\")\n",
    "    \n",
    "    print(f\"[DEBUG] weights.shape: {weights.shape}, gradients.shape: {gradients.shape}\")\n",
    "    weights = weights - learning_rate*gradients\n",
    "    print(f\"[DEBUG] weights.shape: {weights.shape}\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "76ead793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(weights, inputs, outputs, epochs, lr=0.01):\n",
    "    costs = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n=============== epoch: {epoch} ===============\")\n",
    "        z = linear_forward(weights, biases, inputs)\n",
    "        a = activation_linear_forward(z)\n",
    "        gradients = calculate_gradients(a, outputs, inputs)\n",
    "        weights = update_weights(weights, gradients, lr)\n",
    "        cost = cross_entropy_loss(outputs, a)\n",
    "        costs.append(cost)\n",
    "        print(f\"cost:{cost}\")\n",
    "    \n",
    "    \n",
    "    y_hat = np.around(a).reshape(outputs.shape)\n",
    "    print(f\"classification_report:\\n{classification_report(outputs, y_hat)}\")\n",
    "    plt.plot(range(epochs), costs)\n",
    "    \n",
    "    return weights, biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c9516578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(input_size):\n",
    "    weights = np.random.random((1, input_size))\n",
    "    return weights\n",
    "\n",
    "def init_biases():\n",
    "    biases = np.zeros((1,1))\n",
    "    return biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7cb2712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (100, 4)\n",
      "y.shape: (100,)\n",
      "X_train.shape: (80, 4)\n",
      "y_train.shape: (80,)\n",
      "X_test.shape: (20, 4)\n",
      "y_test.shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y =  iris.target.reshape(len(iris.target), 1)\n",
    "\n",
    "to_remove = y!=2\n",
    "X = X[to_remove.reshape(1,150)[0]]\n",
    "y = y[to_remove]\n",
    "\n",
    "X_train = X[:80]\n",
    "y_train = y[:80]\n",
    "\n",
    "X_test = X[80:]\n",
    "y_test = y[80:]\n",
    "\n",
    "print(f\"X.shape: {X.shape}\")\n",
    "print(f\"y.shape: {y.shape}\")\n",
    "\n",
    "print(f\"X_train.shape: {X_train.shape}\")\n",
    "print(f\"y_train.shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"X_test.shape: {X_test.shape}\")\n",
    "print(f\"y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8d9c5f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape: (1, 4)\n",
      "biases.shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "weights = init_weights(X.shape[1])\n",
    "biases = init_biases()\n",
    "\n",
    "print(f\"weights.shape: {weights.shape}\")\n",
    "print(f\"biases.shape: {biases.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5161c331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== epoch: 0 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:2.7662230992579557\n",
      "\n",
      "=============== epoch: 1 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:5.85388171586437\n",
      "\n",
      "=============== epoch: 2 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.23706036547190587\n",
      "\n",
      "=============== epoch: 3 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:1.0270683376101555\n",
      "\n",
      "=============== epoch: 4 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:4.079849317741877\n",
      "\n",
      "=============== epoch: 5 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:2.926478992726553\n",
      "\n",
      "=============== epoch: 6 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.8586520780454653\n",
      "\n",
      "=============== epoch: 7 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:1.8983041515252788\n",
      "\n",
      "=============== epoch: 8 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.7933150879374342\n",
      "\n",
      "=============== epoch: 9 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.6666411935212366\n",
      "\n",
      "=============== epoch: 10 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.14895870638987416\n",
      "\n",
      "=============== epoch: 11 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.004763010938943721\n",
      "\n",
      "=============== epoch: 12 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.00425957958400659\n",
      "\n",
      "=============== epoch: 13 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.003875479087768305\n",
      "\n",
      "=============== epoch: 14 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0035746522730493117\n",
      "\n",
      "=============== epoch: 15 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0033342706784197625\n",
      "\n",
      "=============== epoch: 16 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0031391339276299803\n",
      "\n",
      "=============== epoch: 17 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002978705405346732\n",
      "\n",
      "=============== epoch: 18 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0028454373162204987\n",
      "\n",
      "=============== epoch: 19 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0027337730825975504\n",
      "\n",
      "=============== epoch: 20 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.00263952674593906\n",
      "\n",
      "=============== epoch: 21 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002559482494878019\n",
      "\n",
      "=============== epoch: 22 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002491128011425072\n",
      "\n",
      "=============== epoch: 23 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0024324720217477652\n",
      "\n",
      "=============== epoch: 24 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0023819164388157094\n",
      "\n",
      "=============== epoch: 25 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002338164836364229\n",
      "\n",
      "=============== epoch: 26 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.0023001556679284937\n",
      "\n",
      "=============== epoch: 27 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002267012691987083\n",
      "\n",
      "=============== epoch: 28 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002238007586605028\n",
      "\n",
      "=============== epoch: 29 ===============\n",
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 80)\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 80)\n",
      "[DEBUG] a.shape: (1, 80)\n",
      "\n",
      "[DEBUG] calculate_gradient -----\n",
      "[DEBUG] activations.shape: (1, 80), y.shape: (1, 80), X.shape: (80, 4)\n",
      "[DEBUG] gradients.shape: (1, 4)\n",
      "\n",
      "[DEBUG] update_weights -----\n",
      "[DEBUG] weights.shape: (1, 4), gradients.shape: (1, 4)\n",
      "[DEBUG] weights.shape: (1, 4)\n",
      "\n",
      "[DEBUG] cross_entropy_loss -----\n",
      "[DEBUG] y.shape: (1, 80), y_hat.shape: (1, 80)\n",
      "cost:0.002212531347717478\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights, biases = train(weights, inputs=X_train, outputs=y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c7294203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, weights, biases):\n",
    "    z = linear_forward(weights, biases, X)\n",
    "    a = activation_linear_forward(z)\n",
    "    \n",
    "    y_hat = np.around(a).reshape(y.shape)\n",
    "    print(f\"\\nclassification_report:\\n{classification_report(y, y_hat)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5e1f550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] linear_forward -----\n",
      "[DEBUG] weights.shape: (1, 4), biases.shape: (1, 1), inputs.shape: (4, 20)\n",
      "[DEBUG] z.shape: (1, 20)\n",
      "\n",
      "[DEBUG] activation_linear_forward -----\n",
      "[DEBUG] z.shape: (1, 20)\n",
      "[DEBUG] a.shape: (1, 20)\n",
      "\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(X_test, y_test, weights, biases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
